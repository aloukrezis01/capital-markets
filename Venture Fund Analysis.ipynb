{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1697c6ea-d05c-4eb3-aae5-d249b64caaf8",
   "metadata": {},
   "source": [
    "# Venture Fund Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b819a9c9-4720-4920-9372-584d71b4d645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Stock Symbol  Type  Shares Held  Market Value  \\\n",
      "0        Snowflake  inc.   SNOW   NaN     32221080    7387649000   \n",
      "1  Uber technologies inc   UBER   NaN     28411000    1548684000   \n",
      "2   Meta platforms  inc.     FB   NaN      3753400    1105489000   \n",
      "3      Expedia group inc   EXPE   NaN      2513568     432635000   \n",
      "4        Microsoft corp.   MSFT   NaN      1763135     415694000   \n",
      "\n",
      "   % of Portfolio  Previous % of Portfolio  Ranking  Change in shares  \\\n",
      "0         52.8279                  24.7121      1.0          22729505   \n",
      "1         11.0744                  13.4062      2.0                 0   \n",
      "2          7.9052                   9.4861      3.0                 0   \n",
      "3          3.0937                   4.9321      4.0          -1512617   \n",
      "4          2.9726                   3.1653      5.0            225000   \n",
      "\n",
      "     % Change Change Type % Ownership Qtr first owned                  sector  \\\n",
      "0  239.470320    addition   63.552426         Q3 2020  INFORMATION TECHNOLOGY   \n",
      "1    0.000000         NaN   1.5287016         Q2 2019  CONSUMER DISCRETIONARY   \n",
      "2    0.000000         NaN   0.1560374         Q1 2018          COMMUNICATIONS   \n",
      "3  -37.569486   reduction   1.8169351         Q4 2013  CONSUMER DISCRETIONARY   \n",
      "4   14.628105    addition   0.0233769         Q1 2018  INFORMATION TECHNOLOGY   \n",
      "\n",
      "   source_type  source_date  Avg Price  \n",
      "0          NaN          NaN   244.2357  \n",
      "1          NaN          NaN    30.9000  \n",
      "2          NaN          NaN   141.6100  \n",
      "3          NaN          NaN    97.2900  \n",
      "4          NaN          NaN   180.9841  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Set the relative path to the 'Historical_Data_13F' folder\n",
    "directory = './Historical_Data_13F_Updated/venture_funds'\n",
    "\n",
    "# List all CSV files in the 'Historical_Data_13F' directory\n",
    "csv_files = [file for file in os.listdir(directory) if file.endswith('.csv')]\n",
    "\n",
    "# Check if we have any CSV files to process\n",
    "if csv_files:\n",
    "    # Build the full file path for the first CSV file\n",
    "    first_csv_path = os.path.join(directory, csv_files[0])\n",
    "\n",
    "    # Load the first CSV file into a DataFrame\n",
    "    df = pd.read_csv(first_csv_path)\n",
    "\n",
    "    # Print the first few rows of the DataFrame\n",
    "    print(df.head())\n",
    "else:\n",
    "    print(\"No CSV files found in the directory.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7d5c31-ba10-4fad-bc4f-cc61a0e78c30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "76d11e6c-7b29-4447-8b6c-b2f72ad0d1f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Ticker  altimeter-2021_q1  altimeter-2019_q4  coatue-2019_q3  \\\n",
      "0   SNOW                  1                  0               0   \n",
      "1   UBER                  1                  1               1   \n",
      "2     FB                  1                  1               1   \n",
      "3   EXPE                  1                  1               0   \n",
      "4   MSFT                  1                  1               1   \n",
      "\n",
      "   altimeter-2021_q2  altimeter-2021_q3  coatue-2021_q4  coatue-2019_q4  \\\n",
      "0                  1                  1               1               0   \n",
      "1                  1                  1               1               1   \n",
      "2                  1                  1               1               1   \n",
      "3                  1                  1               0               1   \n",
      "4                  1                  1               1               1   \n",
      "\n",
      "   altimeter-2019_q3  coatue-2021_q1  ...  tiger_global-2021_q1  \\\n",
      "0                  0               1  ...                     1   \n",
      "1                  1               1  ...                     1   \n",
      "2                  1               1  ...                     1   \n",
      "3                  1               1  ...                     0   \n",
      "4                  1               1  ...                     1   \n",
      "\n",
      "   dragoneer-2019_q4  dragoneer-2021_q2  tiger_global-2021_q3  \\\n",
      "0                  0                  1                     1   \n",
      "1                  1                  1                     1   \n",
      "2                  1                  1                     1   \n",
      "3                  0                  0                     0   \n",
      "4                  0                  0                     1   \n",
      "\n",
      "   tiger_global-2021_q2  dragoneer-2021_q3  dragoneer-2019_q3  \\\n",
      "0                     1                  1                  0   \n",
      "1                     1                  1                  1   \n",
      "2                     1                  1                  1   \n",
      "3                     0                  0                  0   \n",
      "4                     1                  0                  0   \n",
      "\n",
      "   tiger_global-2019_q3  dragoneer-2021_q4  tiger_global-2021_q4  \n",
      "0                     0                  1                     1  \n",
      "1                     1                  1                     1  \n",
      "2                     1                  1                     1  \n",
      "3                     0                  0                     0  \n",
      "4                     1                  0                     1  \n",
      "\n",
      "[5 rows x 41 columns]\n"
     ]
    }
   ],
   "source": [
    "# Path to the directory containing CSV files\n",
    "directory = './Historical_Data_13F_Updated/venture_funds'\n",
    "\n",
    "# Initialize an empty dictionary to store the ticker presence data\n",
    "ticker_presence = {}\n",
    "\n",
    "# Get all CSV files from the directory\n",
    "csv_files = [f for f in os.listdir(directory) if f.endswith('.csv')]\n",
    "\n",
    "# Iterate over the files and extract unique tickers\n",
    "for csv_file in csv_files:\n",
    "    # Strip the '.csv' extension for use as DataFrame column names\n",
    "    clean_file_name = csv_file.replace('.csv', '')\n",
    "\n",
    "    file_path = os.path.join(directory, csv_file)\n",
    "    df = pd.read_csv(file_path)\n",
    "    unique_tickers = df['Symbol'].unique()\n",
    "    \n",
    "    # Update the ticker presence for each file\n",
    "    for ticker in unique_tickers:\n",
    "        if ticker not in ticker_presence:\n",
    "            # Initialize a new entry in the dictionary with the cleaned file names\n",
    "            ticker_presence[ticker] = {clean_name: 0 for clean_name in [name.replace('.csv', '') for name in csv_files]}\n",
    "        # Mark the presence of the ticker in the current file\n",
    "        ticker_presence[ticker][clean_file_name] = 1\n",
    "\n",
    "# Create a DataFrame from the ticker presence dictionary\n",
    "one_hot_encoded_df = pd.DataFrame.from_dict(ticker_presence, orient='index')\n",
    "\n",
    "# Reset the index to get tickers as a column instead of an index\n",
    "one_hot_encoded_df.reset_index(inplace=True)\n",
    "one_hot_encoded_df.rename(columns={'index': 'Ticker'}, inplace=True)\n",
    "\n",
    "# Save the one_hot_encoded_df DataFrame to a CSV file\n",
    "one_hot_encoded_df.to_csv('venture_fund_encoded_data.csv', index=False)\n",
    "\n",
    "# Print the first few rows of the one-hot encoded DataFrame to verify\n",
    "print(one_hot_encoded_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb5f633-5029-45c8-be13-53c2207b293a",
   "metadata": {},
   "source": [
    "## Isolating Tickers to Pull Updated Historical Data\n",
    "\n",
    "This being a dynamic analysis with updating information each quarter, the holdings within the funds and the historical pricing data of each financial instrument changes. Because of this, we are going to pull a list of all the unique individual tickers and run them through whatever data provider, scraper, or API can give us historical pricing. Because I do not have access to a tool like Bloomberg for example, I am going to pull them from [Yahoo Finance](http://localhost:8888/lab/tree/Documents/Github/capital-markets/Yahoo%20Finance%20API%20Data%20Pull.ipynb), which you can access using the provided link.\n",
    "\n",
    "Once doing so, we are going to update that information, place them into the Historical Data folder, which we will then access, clean and create a new dataframe inside of this project to access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "46ccf0a9-4b15-418e-b20b-2ba91be44f4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Ticker\n",
      "0   SNOW\n",
      "1   UBER\n",
      "2     FB\n",
      "3   EXPE\n",
      "4   MSFT\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Extract the 'Ticker' column into a new DataFrame\n",
    "tickers_df = pd.DataFrame(one_hot_encoded_df['Ticker'])\n",
    "\n",
    "# Display the first few rows to verify\n",
    "print(tickers_df.head())\n",
    "\n",
    "# If you want to save this to a new CSV file:\n",
    "#tickers_df.to_csv('list_of_tickers.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832b5c00-17d9-4788-867c-a74024196328",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3cefad-1ba7-4f6c-9a1e-23e853364342",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5cba539-4e08-4a6d-b1ce-c024337837e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e56b6ec-de48-4306-820c-fb8b6410d1e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f082801-aa4d-4351-b593-43ab59b1c431",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1bb42be-0a34-4c4a-a8f0-b0dbe46f99bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
