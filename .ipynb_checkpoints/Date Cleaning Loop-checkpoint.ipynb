{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abb69256-7597-4bcf-8e5d-4d11cfa5778a",
   "metadata": {},
   "source": [
    "# Date Cleaning Loop for Data Pulled from Yahoo Finance API\n",
    "\n",
    "\n",
    "### Background\n",
    "\n",
    "Sometimes when one is trying to work with historical data, formatting doesn't map directly from one dataset to another. In scenerios like this we need to clean and transform the data so that they can be mapped together. Date formatting is a common example where the data type can be formatted in different ways, (MM-DD-YY, MM-DD-YYYY, MM/DD/YY, MM/DD/YYYY, YY-MM-DD, etc.) and can create all kinds of problems when combining datasets with one another and going about the initial steps of data exploration and data cleaning.\n",
    "\n",
    "In this specific script, I was initially trying to transoform the Date columns within the dataframe, merging them together and receiving error messages for having wrong formatting. Rather, I found if I was to turn the dataframes back into CSVs, and then retrieve that same information from the CSV file.\n",
    "\n",
    "\n",
    "### Summary\n",
    "\n",
    "This python script transforms the data in the \"Date Column\" which comes up as the following <i>\"2007-11-15 00:00:00-05:00\"</i>, removes the time component and just keeps the date in YYYY-MM-DD format, this example being <i>\"2007-11-15\"</i>.\n",
    "\n",
    "After doing so, we are going to save the updated dataframe into a new CSV file in a new folder. Because we are working with multiple CSV files for data regarding multiple financial instruments that are from the same data source and have the same structure and formatting, we are going to use a loop so that we can apply it to all CSV files and populate these new files into a new, seperate folder.\n",
    "\n",
    "\n",
    "### Process\n",
    "\n",
    "To address this issue and ensure seamless integration with other time series datasets, we are implementing a data cleaning loop specifically designed to process the files obtained from the Yahoo Finance API. This loop will:\n",
    "\n",
    "1. Identify and isolate the \"Date\" column in each dataset.\n",
    "2. Remove any extraneous text from the \"Date\" values, leaving only the date information.\n",
    "3. Convert the cleaned date strings into the datetime64 format, ensuring uniformity with standard time series data formats.\n",
    "\n",
    "<b>Example:<b>\n",
    "```javascript\n",
    "df['Date'] = df['Date'].str.split(' ').str[0]\n",
    "```\n",
    "\n",
    "By standardizing the date format across all datasets, we enhance the compatibility and reliability of our data merges. This, in turn, facilitates more accurate and insightful data analysis and visualization, allowing us to derive meaningful insights from the combined datasets with greater efficiency and less manual intervention.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2657dd4-0f0a-46e7-b504-eee694dcf682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# CSV files all from Yahoo Finance API in the \"Historical_Data_Prices\" folder to the new \"Historical_Data_Prices_Cleaned\" folder\n",
    "input_directory = 'Historical_Data_Prices'\n",
    "output_directory = 'Historical_Data_Prices_Cleaned'\n",
    "\n",
    "# If this is a new folder\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Use glob to find all CSV files in the input directory\n",
    "csv_files = glob.glob(os.path.join(input_directory, '*.csv'))\n",
    "\n",
    "# Process each CSV file\n",
    "for file_path in csv_files:\n",
    "    # Load the CSV file into a DataFrame\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Check if 'Date' column exists\n",
    "    if 'Date' in df.columns:\n",
    "        # Apply the string split operation to the 'Date' column\n",
    "        df['Date'] = df['Date'].str.split(' ').str[0]\n",
    "        \n",
    "        # Define the new path for the cleaned CSV file\n",
    "        file_name = os.path.basename(file_path)\n",
    "        cleaned_file_path = os.path.join(output_directory, file_name)\n",
    "        \n",
    "        # Save the cleaned DataFrame to a new CSV file in the output directory\n",
    "        df.to_csv(cleaned_file_path, index=False)\n",
    "\n",
    "print(f\"Done.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
