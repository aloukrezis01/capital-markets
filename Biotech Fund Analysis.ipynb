{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "484b7082-93b5-4a4d-a530-4c3c46c0a45d",
   "metadata": {},
   "source": [
    "# Biotech Fund Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f6f6d0e9-eeb7-45a5-99ef-b2799818c08d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Stock Symbol  Type  Shares Held  Market Value  % of Portfolio  \\\n",
      "0    Tesla inc   TSLA   NaN    2047283.0  1.398601e+09          5.4757   \n",
      "1   Square inc     SQ   NaN    5500423.0  1.341553e+09          5.2524   \n",
      "2     Roku inc   ROKU   NaN    2213307.0  1.014912e+09          3.9735   \n",
      "3  Shopify inc   SHOP   NaN     692044.0  1.010391e+09          3.9558   \n",
      "4   Twilio inc   TWLO   NaN    2409154.0  9.489560e+08          3.7153   \n",
      "\n",
      "   Previous % of Portfolio  Ranking  Change in shares   % Change Change Type  \\\n",
      "0                   5.2193      1.0          452193.0  28.349059    addition   \n",
      "1                   6.2982      2.0         -161931.0  -2.859782   reduction   \n",
      "2                   3.4691      3.0           39557.0   1.819758    addition   \n",
      "3                   2.9875      4.0          140913.0  25.567968    addition   \n",
      "4                   2.7628      5.0          754116.0  45.564875    addition   \n",
      "\n",
      "   % Ownership Qtr first owned                  sector  source_type  \\\n",
      "0     0.206793         Q1 2018  CONSUMER DISCRETIONARY          NaN   \n",
      "1     1.384116         Q4 2016                 FINANCE          NaN   \n",
      "2     1.901392         Q3 2019  INFORMATION TECHNOLOGY          NaN   \n",
      "3     0.610787         Q3 2020          COMMUNICATIONS          NaN   \n",
      "4     1.443201         Q1 2019  INFORMATION TECHNOLOGY          NaN   \n",
      "\n",
      "   source_date  Avg Price  \n",
      "0          NaN   293.6590  \n",
      "1          NaN    95.5700  \n",
      "2          NaN   143.3388  \n",
      "3          NaN  1187.1124  \n",
      "4          NaN   300.9507  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Set the relative path to the 'Historical_Data_13F' folder\n",
    "directory = './Historical_Data_13F'\n",
    "\n",
    "# List all CSV files in the 'Historical_Data_13F' directory\n",
    "csv_files = [file for file in os.listdir(directory) if file.endswith('.csv')]\n",
    "\n",
    "# Check if we have any CSV files to process\n",
    "if csv_files:\n",
    "    # Build the full file path for the first CSV file\n",
    "    first_csv_path = os.path.join(directory, csv_files[0])\n",
    "\n",
    "    # Load the first CSV file into a DataFrame\n",
    "    df = pd.read_csv(first_csv_path)\n",
    "\n",
    "    # Print the first few rows of the DataFrame\n",
    "    print(df.head())\n",
    "else:\n",
    "    print(\"No CSV files found in the directory.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "60616e93-078d-4591-81a2-31b0e782be4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baker_Bros unique tickers:\n",
      "['KYMR', 'CCXI', 'EXAS', 'ALLK', 'KRYS', 'BCEL', 'VERV', 'HOOK', 'NXTC', 'LPTX', 'CYT', 'ACHL', 'ALEC', 'NERV', 'SBTX', 'DEBT-TRIC', 'VYNE', 'CBAY', 'ARGX', 'TIL', 'BCRX', 'INSM', 'IMCR', 'RARE', 'XLRN', 'FOMX1', 'CRNX', 'NEXI', 'GOSS', 'KNSA', 'CHMA1', 'TARA', 'IFRX', 'YMAB', 'LJPC', 'KOD', 'BLCM', 'NGM', 'TNGX', 'ITOS', 'ALT', 'HARP', 'ABCL', 'HRMY', 'PRLD', 'AUTL', 'ASMB', 'GLPG', 'NTLA', 'RLMD', 'SRZNW', 'TPST', 'INZY', 'XENE', 'FPRX', 'ADCT', 'INCY', 'CERS', 'PACB', 'OYST', 'DICE', 'QURE', 'RYTM', 'ATHA', 'BMEA', 'RCUS', 'CABA', 'KURA', 'ISEE', 'TRIL', 'SGEN', 'MRKR', 'ARAV', 'ALBO', 'SERA', 'MIRM', 'NVAX', 'AXSM', 'CYCN', 'VXRT', 'DOVA', 'SNDX', 'SRRA', 'RETA', 'ASND', 'FSTX', 'CNTA', 'ALRN', 'SYRS', 'XBIT', 'CTMX', 'AQST', 'VINC', 'VIRX', 'DSGN', 'BCAB', 'PTGX', 'QLGN', 'ALXN', 'AMRN', 'BDSI', 'DVAX', 'NBIX', 'HALO', 'ALXN1', 'DEBT-APEL', 'AGLE', 'AMYT', 'APLT', 'MDGL', 'NRIX', 'SRZN', 'VKTX', 'OTIC', 'LIFE', 'AKRO', 'MYOK1', 'FREQ', 'GLMD', 'NLTX', 'HZNP', 'ONCE', 'GMDA', 'AIMT1', 'LOGC', 'ABEO', 'MRUS', 'AFMD', 'CNST', 'GWPH', 'DRNA', 'ORTX', 'FMTX', 'IDRA', 'ACHN', 'GTH', 'TLIS', 'DEBT-INVI', 'MTNB', 'RARX1', 'ADMS', 'DEBT-INSM', 'GBT', 'DERM1', 'FGEN', 'EWTX', '4A3:FWB', 'ALKS', 'FLGT', 'RVMD', 'MIST', 'SGMO', 'TCDA', 'LEGN', 'INFI', 'AUPH', 'NVTA', 'PRNB1', 'ARRY1', 'BLUE', 'PASG', 'TCRX', 'IDYA', 'XNCR', 'AVTE', 'URGN', 'KZR', 'KRTX', 'REPL', 'TRDA', 'IMTX', 'BOLD', 'IMMU1', 'OPT', 'ACAD', 'ALGS', 'TCRR', 'OVID', 'IGMS', 'MGNX', 'DNLI', 'TSVT', 'ZYME', 'FHTX', 'DBVT', 'BNR', 'UROV1', 'ADAP', 'BMRN', 'GHDX', 'TVTX', 'HRTX', 'VSTM', 'KDNY', 'APLS', 'ACOR', 'MTEM', 'GNFT', 'CPRX', 'CHMA', 'MREO', 'EVFM', 'GTHX', 'MRTX', 'SRPT', 'ANAB', 'BGNE', 'ADPT', 'FTSV1']\n",
      "\n",
      "Casdin_Capital unique tickers:\n",
      "['EXAS', 'VERV', 'ZLAB', 'ALEC', 'SLGC', 'SAGE', 'ORIC', 'BEAM', 'EDIT', 'AMRS', 'OMIC', 'TKNO', 'TNYA', 'TNGX', 'GILD', 'ABCL', 'BLFS', 'NEO', 'SNCE', 'DNA', 'EXAI', 'DCPH', 'ADVM', 'EQRX', 'PACB', 'KRON', 'FULC', 'CRSP', 'TWST', 'DYN', 'ABSI', 'IPSC', 'BPMC', 'SNDX', 'GBIO', 'STOK', 'GLUE', 'RXRX', 'MASS', 'SMFR', 'NAUT', 'GH', 'CDXS', 'DMTK', 'CCCC', 'MYOK1', 'GRTS', 'BMYR', 'ONCE', 'RLAY', 'BDTX', 'CNST', 'ORTX', 'IOVA', 'CLOV', 'GBT', 'BLI', 'TPTX', 'CDAK', 'ALNY', 'FIXX', 'RVMD', 'SGMO', 'LEGN', 'NVTA', 'BLUE', 'VRTX', 'DBTX', 'CDNA', 'BOLD', 'MXCT', 'TSHA', 'AGIO', 'DNLI', 'FHTX', 'ZYME', 'BNR', 'ALLO', 'ME', 'GNMK1', 'ZY', 'ILMN', 'LIAN', 'VYGR', 'FATE', 'SEER', 'SANA', 'FDMT', 'SRPT', 'ADPT', 'BGNE', 'MGTA']\n",
      "\n",
      "Orbimed unique tickers:\n",
      "['ALDR', 'ZLAB', 'ALEC', 'ORIC', 'RXST', 'KPTI', 'RXDX', 'ZBH', 'CRNX', 'DHR/PB', 'BHC', 'ANNX', 'HUM', 'ANTM', 'NVO', 'APTX', 'XENE', 'HUMA', 'CVM', 'INCY', 'PMVP', 'KALV', 'JANX', 'UNH', 'ISEE', 'ALHC', 'AVRO', 'NPCE', 'IMRA', 'MAPSW', 'ELDN', 'LABP', 'MASS', 'TALS', 'THRX', 'BSX', 'NBRV', 'NBIX', 'ALPN', 'ALXN1', 'NAUT', 'CTKB', 'GH', 'KALA', 'MBIO', 'IBB', 'NUVB', 'GLTO', 'PRAX', 'HZNP', 'BMYR', 'LOGC', 'AVTR', 'GRAY', 'RUBY', 'CALT', 'DERM1', 'MGTX', 'EPIX', 'TNDM', 'ADAG', 'MIST', 'RVMD', 'BFYT', 'PRNB1', 'AUPH', 'PFE', 'IMMU1', 'CYBN', 'LRMR', 'CMPS', 'ACAD', 'IGMS', 'ZYME', 'ADAP', 'ILMN', 'HSAQ', 'COGT', 'CRIS', 'MRK', 'MREO', 'OM', 'ALXO', 'SRPT', 'SYK', 'ANAB', 'CLDX', 'HAE', 'DHR+B', 'PRCT', 'ISRG', 'TXG', 'VYNE', 'ARGX', 'FOMX1', 'GRCL', 'NSTG', 'ATNX', 'CMPX', 'DRUG', 'BLU:TSE', 'IFRX', 'TARA', 'GILD', 'ATXS', 'HARP', 'GLPG', 'OWLT', 'INZY', 'DCPH', 'ACET', 'ADVM', 'CRBP', 'OBSV', 'RYTM', 'SGEN', 'HCA', 'CHNG', 'MIRM', 'RGNX', 'DYN', 'EW', 'SNDX', 'CGEM', 'RETA', 'REGN', 'ASND', 'FUSN', 'XLV', 'CVRX', 'DVAX', 'NBTX', 'BLRX', 'IKNA', 'ICPT', 'AGLE', 'NMTR', 'FLDM', 'APLT', 'PFNX1', 'BIIB', 'NRIX', 'SONX', 'ZGNX', 'RLAY', 'CVAC', 'VRNA', 'TCDA', 'ARWR', 'ABBV', 'VTYX', 'VRTX', 'AGRX', 'RPTX', 'SGFY', 'KZR', 'SURF', 'TCRR', 'OGN', 'OCX', 'SLQT', 'BMY', 'PGNY', 'BNR', 'DEBT-NANO', 'GMTX', 'ARQL', 'IQV', 'CBIO', 'IMGN', 'SANA', 'NVTR1', 'GHRS', 'CMMB', 'NTRA', 'XTNT', 'MRTX', 'RLM1', 'CNC', 'VERV', 'NXTC', 'IKNA-NV', 'ACHL', 'SAVA', 'INSM', 'PRLD-NV', 'OMIC', 'AVDR1', 'XLRN', 'IONS', 'ALC', 'PTCT', 'CALA', 'PRLD', 'ATRC', 'ASMB', 'SWTX', 'NTLA', 'BSX+A', 'MAPS', 'OLK', 'DICE', 'THC', 'QURE', 'STRO', 'RCUS', 'CABA', 'TRIL', 'MRSN', 'ALBO', 'TAK', 'XBI', 'NVAX', 'AXSM', 'SCPH', 'HCAT', 'STOK', 'SYRS', 'SGHT', 'CTMX', 'ACHC', 'TERN', 'SPRO', 'CLVS', 'GLUE', 'PTGX', 'AUGX', 'ARNA', 'FOLD', 'VTRS', 'INNV', 'VOR', 'ARQT', 'EXEL', 'OTIC', 'AZN', 'DXCM', 'IMVT', 'SEM', 'MYOV', 'ARVN', 'PCVX', 'CNST', 'SNY', 'EHTH', 'GRPH', 'RARX1', 'TPTX', 'TELA', 'ETNB', 'EWTX', 'ERAS', 'ABT', 'SELB', 'AVTE', 'AADI', 'OWLT.WS', 'BOLD', 'THOR', 'PPBT', 'XENT', 'CI', 'INSP', 'GNMK1', 'TVTX', 'HRTX', 'MDCO1', 'APLS', 'PSNL', 'APTO', 'SPY', 'PAND1', 'FDMT', 'KYMR', 'ACRS', 'RAPT', 'KRYS', 'TEVA', 'KROS', 'SBTX', 'NBSE', 'WMGI2', 'RARE', 'TMO', 'SIBN', 'CRVS', 'OSH', 'GOSS', 'SBBP1', 'PHAS', 'ABCL', 'RCKT', 'RGEN', 'PYXS', 'ENDP', 'EXAI', 'GKOS', 'VECT', 'MRNS', 'CARA', 'VRCA', 'TBPH', 'SYBX', 'CRSP', 'A', 'JNCE', 'XFOR', 'IPSC', 'SRRA', 'SVA1', 'AKUS', 'AMRN', 'FBRX', 'OLMA', 'MYOK1', 'NLTX', 'ONCE', 'LUNG', 'EVH', 'IOVA', 'ARCT', 'AFIB', 'PRTA', 'KNTE', 'FLXN', 'MOH', 'DBTX', 'PASG', 'VRAY', 'BTAI', 'CDNA', 'AGIO', 'ADGI', 'LBPH', 'CNVY', 'PRVL', 'PRQR', 'BMRN', 'IMAB', 'RNA', 'FTRPF', 'KDNY', 'VTGN', 'ASLN', 'MDGS', 'GNFT', 'PBYI', 'AMGN', 'PHGE', 'CTIC', 'ADPT', 'MGTA']\n",
      "\n",
      "Perceptive unique tickers:\n",
      "['NUVL', 'ZIOP', 'SHC', 'MDT', 'ALEC', 'MCRB', 'KPTI', 'AMRS', 'RXDX', 'DNAY', 'ANIP', 'BIO', 'ZBH', 'CRNX', 'GERN', 'BHC', 'KOD', 'HRMY', 'VERU', 'CVET', 'XENE', 'CVM', 'PMVP', 'EQRX', 'ISEE', 'ARAV', 'DEBT-NEVR', 'RVNC', 'LGVW.UN1', 'BPMC', 'HCAQ', 'TYRA', 'LABP', 'MASS', 'VCRA', 'SMFR', 'NBIX', 'SIC1', 'SLGCW', 'EQRXW', 'NAUT', 'GH', 'PRN-CYTO', 'AXNX', 'ZYNE', 'SRZN', 'DMTK', 'AKRO', 'NUVB', 'MMSI', 'HZNP', 'DRNA', 'BBIO', 'PRVB', 'PPH', 'ABEOW', 'TXMD', 'MRVI', 'MGTX', 'RACB', 'ONCR', 'TNDM', 'RVMD', 'CERN', 'AUPH', 'ARRY1', 'IDYA', 'DRIO', 'CMIIU1', 'IMMU1', 'CMPS', 'QTNT', 'ACAD', 'EIDX1', 'STLA', 'ZYME', 'ALLO', 'ADAP', 'CRY', 'TARS', 'HSAQ', 'COGT', 'MTEM', 'CRIS', 'COLL', 'BFLY.WS', 'MREO', 'OM', 'ANAB', 'CLDX', 'EXAS', 'PRCT', 'AVIR', 'TXG', 'SLGC', 'PSTX', 'VYNE', 'TKNO', 'FOMX1', 'ATNX', 'NSTG', 'BLU:TSE', 'EIGR', 'TARA', 'GILD', 'ATXS', 'CMAX', 'INBX', 'PNT', 'HLTH', 'SRZNW', 'DCPH', 'ACET', 'RKLY.WS', 'SILK', 'KRMD', 'RYTM', 'ATHA', 'SGEN', 'MRKR', 'TWST', 'MRNA', 'RGNX', 'DYN', 'NVNO', 'SNDX', 'REGN', 'ASND', 'FUSN', 'MEDP', 'AQST', 'VRDN', 'CVRX', 'DVAX', 'NBTX', 'AORT', 'ICPT', 'HYPR', 'DEBT-COHE', 'FLDM', 'MNTA1', 'OTLKW', 'BIIB', 'SONX', 'PRN-COLL', 'ZGNX', 'FREQ', 'ESTA', 'ZNTL', 'RLAY', 'BDTX', 'VAPO', 'MRUS', 'DALS', 'VRNA', 'CUE', 'FGEN', 'ALNA', 'CEREW', '4A3:FWB', 'LGV.UN', 'MEIP', 'ARWR', 'KDMN', 'AGRX', 'KRTX', 'AVXL', 'WVE', 'TSHA', 'TCRR', 'DNLI', 'HOLX', 'DBVT', 'UROV1', 'BNR', 'DEBT-NANO', 'LIAN', 'ARQL', 'ALDX', 'VYGR', 'RACE', 'ITCI', 'ICVX', 'SANA', 'NTRA', 'MRTX', 'VINCU', 'ISO', 'PHVS', 'CCXI', 'PLXP', 'ALLK', 'ACHL', 'AVDL', 'SAGE', 'SAVA', 'CBAY', 'OMIC', 'XLRN', 'CMAXW', 'TDOC', 'YMAB', 'ATRC', 'CNCE', 'SWTX', 'SNCE', 'DFHTU1', 'DICE', 'THC', 'QURE', 'KRON', 'PHR', 'VBIV', 'TRIL', 'ALBO', 'XBI', 'NVAX', 'AXSM', 'LVGO1', 'SCYX', 'ABSI', 'HCAT', 'STOK', 'SGHT', 'CTMX', 'BLSA', 'PTGX', 'IMGO', 'ARNA', 'FOLD', 'VTRS', 'MDGL', 'ACCD', 'PRVA', 'CCCC', 'IMVTU1', 'DXCM', 'CFMS', 'AKBA', 'IMVT', 'IMRX', 'ARVN', 'PCVX', 'CNST', 'ORTX', 'EHTH', 'TLIS', 'GRPH', 'LYRA', 'VINCW', 'RARX1', 'TPTX', 'RPID', 'OPTN', 'LEGN', 'TBIO', 'REPL', 'CHFW.UN1', 'RAIN', 'CORV.CAD:VALUE', 'PODD', 'TVTX', 'MDCO1', 'UTHR', 'APLS', 'PSNL', 'SPY', 'ATEC', 'GTHX', 'FDMT', 'BGNE', 'MORF', 'KYMR', 'RAPT', 'ACRS', 'LPTX', 'BEAM', 'IMCR', 'AKYA', 'SLDB', 'TMCI', 'VIR', 'TNGX', 'MOTS', 'ITOS', 'ABCL', 'RCKT', 'UTRS', 'RGEN', 'PYXS', 'NVRO', 'VRCA', 'FULC', 'TBPH', 'SYBX', 'CRSP', 'GRTX', 'DAWN', 'NEPT', 'DOVA', 'LMNX1', 'SRRA', 'IPOF', 'VINC', 'BCAB', 'AMRN', 'FBRX', 'ADMA', 'ONEM', 'NVCR', 'CMLTU', 'MYOK1', 'RMTI', 'NARI', 'NLTX', 'ACST', 'IMVTU', 'ONCE', 'LUNG', 'ABEO', 'FMTX', 'IOVA', 'PRTA', 'CLOV', 'GBT', 'TGTX', 'SMIHU', 'NVTA', 'CERE', 'SGTX', 'VRAY', 'AGIO', 'SCPE.UN1', 'MGNX', 'SWAV', 'ZY', 'BMRN', 'SDGR', 'RNA', 'ACOR', 'CHRS', 'ADPT', 'AMWL']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Set the relative path to the folder containing your CSV files\n",
    "directory = './Historical_Data_13F'\n",
    "\n",
    "# Define the funds and initialize a dictionary with an empty set for each fund\n",
    "funds = {\n",
    "    'baker_bros': set(),\n",
    "    'casdin_capital': set(),\n",
    "    'orbimed': set(),\n",
    "    'perceptive': set(),\n",
    "}\n",
    "\n",
    "# Get a list of all CSV files in the directory\n",
    "csv_files = [file for file in os.listdir(directory) if file.endswith('.csv')]\n",
    "\n",
    "# Iterate over each CSV file in the directory\n",
    "for csv_file in csv_files:\n",
    "    # For each fund, check if the fund's name is in the file name\n",
    "    for fund in funds:\n",
    "        if fund in csv_file.lower().replace(' ', '-'):  # replace spaces with underscores to match file naming conventions\n",
    "            # Construct the full file path\n",
    "            file_path = os.path.join(directory, csv_file)\n",
    "            \n",
    "            # Read the CSV file into a DataFrame\n",
    "            df = pd.read_csv(file_path)\n",
    "            \n",
    "            # Extract unique tickers from the 'Symbol' column\n",
    "            unique_tickers = df['Symbol'].unique()\n",
    "            \n",
    "            # Update the unique tickers set for the fund\n",
    "            funds[fund].update(unique_tickers)\n",
    "\n",
    "# Convert the sets to lists if you need lists specifically\n",
    "unique_tickers_lists = {fund: list(tickers) for fund, tickers in funds.items()}\n",
    "\n",
    "# You can now print or return the lists for each fund\n",
    "for fund, tickers in unique_tickers_lists.items():\n",
    "    print(f\"{fund.title()} unique tickers:\")\n",
    "    print(tickers)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec0d06a6-58b8-479d-9bab-1b117470ea60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Ticker  baker_bros  casdin_capital  orbimed  perceptive\n",
      "0   4A3:FWB           1               0        0           1\n",
      "1         A           0               0        1           0\n",
      "2      AADI           0               0        1           0\n",
      "3      ABBV           0               0        1           0\n",
      "4      ABCL           1               1        1           1\n",
      "5      ABEO           1               0        0           1\n",
      "6     ABEOW           0               0        0           1\n",
      "7      ABSI           0               1        0           1\n",
      "8       ABT           0               0        1           0\n",
      "9      ACAD           1               0        1           1\n",
      "10     ACCD           0               0        0           1\n",
      "11     ACET           0               0        1           1\n",
      "12     ACHC           0               0        1           0\n",
      "13     ACHL           1               0        1           1\n",
      "14     ACHN           1               0        0           0\n",
      "15     ACOR           1               0        0           1\n",
      "16     ACRS           0               0        1           1\n",
      "17     ACST           0               0        0           1\n",
      "18     ADAG           0               0        1           0\n",
      "19     ADAP           1               0        1           1\n",
      "20     ADCT           1               0        0           0\n",
      "21     ADGI           0               0        1           0\n",
      "22     ADMA           0               0        0           1\n",
      "23     ADMS           1               0        0           0\n",
      "24     ADPT           1               1        1           1\n",
      "25     ADVM           0               1        1           0\n",
      "26     AFIB           0               0        1           0\n",
      "27     AFMD           1               0        0           0\n",
      "28     AGIO           0               1        1           1\n",
      "29     AGLE           1               0        1           0\n",
      "30     AGRX           0               0        1           1\n",
      "31    AIMT1           1               0        0           0\n",
      "32     AKBA           0               0        0           1\n",
      "33     AKRO           1               0        0           1\n",
      "34     AKUS           0               0        1           0\n",
      "35     AKYA           0               0        0           1\n",
      "36     ALBO           1               0        1           1\n",
      "37      ALC           0               0        1           0\n",
      "38     ALDR           0               0        1           0\n",
      "39     ALDX           0               0        0           1\n",
      "40     ALEC           1               1        1           1\n",
      "41     ALGS           1               0        0           0\n",
      "42     ALHC           0               0        1           0\n",
      "43     ALKS           1               0        0           0\n",
      "44     ALLK           1               0        0           1\n",
      "45     ALLO           0               1        0           1\n",
      "46     ALNA           0               0        0           1\n",
      "47     ALNY           0               1        0           0\n",
      "48     ALPN           0               0        1           0\n",
      "49     ALRN           1               0        0           0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Set the relative path to the folder containing your CSV files\n",
    "directory = './Historical_Data_13F'\n",
    "\n",
    "# Define the funds and initialize a dictionary with an empty set for each fund\n",
    "funds = {\n",
    "    'baker_bros': set(),\n",
    "    'casdin_capital': set(),\n",
    "    'orbimed': set(),\n",
    "    'perceptive': set(),\n",
    "}\n",
    "\n",
    "# Get a list of all CSV files in the directory\n",
    "csv_files = [file for file in os.listdir(directory) if file.endswith('.csv')]\n",
    "\n",
    "# Iterate over each CSV file in the directory\n",
    "for csv_file in csv_files:\n",
    "    # For each fund, check if the fund's name is in the file name\n",
    "    for fund in funds:\n",
    "        if fund in csv_file.lower().replace(' ', '_'):\n",
    "            # Construct the full file path\n",
    "            file_path = os.path.join(directory, csv_file)\n",
    "            \n",
    "            # Read the CSV file into a DataFrame\n",
    "            df = pd.read_csv(file_path)\n",
    "            \n",
    "            # Extract unique tickers from the 'Symbol' column\n",
    "            unique_tickers = df['Symbol'].unique()\n",
    "            \n",
    "            # Update the unique tickers set for the fund\n",
    "            funds[fund].update(unique_tickers)\n",
    "\n",
    "# Combine all unique tickers from all funds into a master list\n",
    "all_unique_tickers = set(ticker for tickers_set in funds.values() for ticker in tickers_set)\n",
    "\n",
    "# Create a DataFrame with all tickers as rows and funds as columns, initialized to 0\n",
    "one_hot_df = pd.DataFrame(0, index=sorted(all_unique_tickers), columns=funds.keys())\n",
    "\n",
    "# Fill in the DataFrame: set 1 where ticker is present in the fund's list\n",
    "for fund, tickers in funds.items():\n",
    "    # Convert the set of tickers to a sorted list before using as an indexer\n",
    "    tickers_list = sorted(list(tickers))\n",
    "    one_hot_df.loc[tickers_list, fund] = 1\n",
    "\n",
    "# Reset the index to make 'Ticker' a column instead of an index\n",
    "one_hot_df.reset_index(inplace=True)\n",
    "one_hot_df.rename(columns={'index': 'Ticker'}, inplace=True)\n",
    "\n",
    "# 'one_hot_df' now contains the desired one-hot encoded DataFrame\n",
    "print(one_hot_df.head(50))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8970cfa4-0059-4c2b-a782-2e9dd477dfd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tickers included in all funds:\n",
      "{'NUVL', 'ZIOP', 'SHC', 'MDT', 'ALEC', 'MCRB', 'KPTI', 'AMRS', 'RXDX', 'DNAY', 'ANIP', 'BIO', 'ZBH', 'CRNX', 'GERN', 'BHC', 'KOD', 'HRMY', 'VERU', 'CVET', 'XENE', 'CVM', 'PMVP', 'EQRX', 'ISEE', 'ARAV', 'DEBT-NEVR', 'RVNC', 'LGVW.UN1', 'BPMC', 'HCAQ', 'TYRA', 'LABP', 'MASS', 'VCRA', 'SMFR', 'NBIX', 'SIC1', 'SLGCW', 'EQRXW', 'NAUT', 'GH', 'PRN-CYTO', 'AXNX', 'ZYNE', 'SRZN', 'DMTK', 'AKRO', 'NUVB', 'MMSI', 'HZNP', 'DRNA', 'BBIO', 'PRVB', 'PPH', 'ABEOW', 'TXMD', 'MRVI', 'MGTX', 'RACB', 'ONCR', 'TNDM', 'RVMD', 'CERN', 'AUPH', 'ARRY1', 'IDYA', 'DRIO', 'CMIIU1', 'IMMU1', 'CMPS', 'QTNT', 'ACAD', 'EIDX1', 'STLA', 'ZYME', 'ALLO', 'ADAP', 'CRY', 'TARS', 'HSAQ', 'COGT', 'MTEM', 'CRIS', 'COLL', 'BFLY.WS', 'MREO', 'OM', 'ANAB', 'CLDX', 'EXAS', 'PRCT', 'AVIR', 'TXG', 'SLGC', 'PSTX', 'VYNE', 'TKNO', 'FOMX1', 'ATNX', 'NSTG', 'BLU:TSE', 'EIGR', 'TARA', 'GILD', 'ATXS', 'CMAX', 'INBX', 'PNT', 'HLTH', 'SRZNW', 'DCPH', 'ACET', 'RKLY.WS', 'SILK', 'KRMD', 'RYTM', 'ATHA', 'SGEN', 'MRKR', 'TWST', 'MRNA', 'RGNX', 'DYN', 'NVNO', 'SNDX', 'REGN', 'ASND', 'FUSN', 'MEDP', 'AQST', 'VRDN', 'CVRX', 'DVAX', 'NBTX', 'AORT', 'ICPT', 'HYPR', 'DEBT-COHE', 'FLDM', 'MNTA1', 'OTLKW', 'BIIB', 'SONX', 'PRN-COLL', 'ZGNX', 'FREQ', 'ESTA', 'ZNTL', 'RLAY', 'BDTX', 'VAPO', 'MRUS', 'DALS', 'VRNA', 'CUE', 'FGEN', 'ALNA', 'CEREW', '4A3:FWB', 'LGV.UN', 'MEIP', 'ARWR', 'KDMN', 'AGRX', 'KRTX', 'AVXL', 'WVE', 'TSHA', 'TCRR', 'DNLI', 'HOLX', 'DBVT', 'UROV1', 'BNR', 'DEBT-NANO', 'LIAN', 'ARQL', 'ALDX', 'VYGR', 'RACE', 'ITCI', 'ICVX', 'SANA', 'NTRA', 'MRTX', 'VINCU', 'ISO', 'PHVS', 'CCXI', 'PLXP', 'ALLK', 'ACHL', 'AVDL', 'SAGE', 'SAVA', 'CBAY', 'OMIC', 'XLRN', 'CMAXW', 'TDOC', 'YMAB', 'ATRC', 'CNCE', 'SWTX', 'SNCE', 'DFHTU1', 'DICE', 'THC', 'QURE', 'KRON', 'PHR', 'VBIV', 'TRIL', 'ALBO', 'XBI', 'NVAX', 'AXSM', 'LVGO1', 'SCYX', 'ABSI', 'HCAT', 'STOK', 'SGHT', 'CTMX', 'BLSA', 'PTGX', 'IMGO', 'ARNA', 'FOLD', 'VTRS', 'MDGL', 'ACCD', 'PRVA', 'CCCC', 'IMVTU1', 'DXCM', 'CFMS', 'AKBA', 'IMVT', 'IMRX', 'ARVN', 'PCVX', 'CNST', 'ORTX', 'EHTH', 'TLIS', 'GRPH', 'LYRA', 'VINCW', 'RARX1', 'TPTX', 'RPID', 'OPTN', 'LEGN', 'TBIO', 'REPL', 'CHFW.UN1', 'RAIN', 'CORV.CAD:VALUE', 'PODD', 'TVTX', 'MDCO1', 'UTHR', 'APLS', 'PSNL', 'SPY', 'ATEC', 'GTHX', 'FDMT', 'BGNE', 'MORF', 'KYMR', 'RAPT', 'ACRS', 'LPTX', 'BEAM', 'IMCR', 'AKYA', 'SLDB', 'TMCI', 'VIR', 'TNGX', 'MOTS', 'ITOS', 'ABCL', 'RCKT', 'UTRS', 'RGEN', 'PYXS', 'NVRO', 'VRCA', 'FULC', 'TBPH', 'SYBX', 'CRSP', 'GRTX', 'DAWN', 'NEPT', 'DOVA', 'LMNX1', 'SRRA', 'IPOF', 'VINC', 'BCAB', 'AMRN', 'FBRX', 'ADMA', 'ONEM', 'NVCR', 'CMLTU', 'MYOK1', 'RMTI', 'NARI', 'NLTX', 'ACST', 'IMVTU', 'ONCE', 'LUNG', 'ABEO', 'FMTX', 'IOVA', 'PRTA', 'CLOV', 'GBT', 'TGTX', 'SMIHU', 'NVTA', 'CERE', 'SGTX', 'VRAY', 'AGIO', 'SCPE.UN1', 'MGNX', 'SWAV', 'ZY', 'BMRN', 'SDGR', 'RNA', 'ACOR', 'CHRS', 'ADPT', 'AMWL'}\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'one_hot_df' is your one-hot encoded DataFrame\n",
    "\n",
    "# Identify tickers that have a 1 in every fund's column\n",
    "# This will be true if the sum of 1's for a ticker equals the number of funds\n",
    "num_funds = len(one_hot_df.columns) - 1  # Subtract 1 to exclude the 'Ticker' column\n",
    "tickers_in_all_funds = one_hot_df[one_hot_df.iloc[:, 1:].sum(axis=1) == num_funds]['Ticker']\n",
    "\n",
    "# Convert the result to a list\n",
    "tickers_in_all_funds_list = tickers_in_all_funds.tolist()\n",
    "\n",
    "# Print the list of tickers that are included in all funds\n",
    "print(\"Tickers included in all funds:\")\n",
    "print(tickers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5cbaac03-2cdd-4c54-9997-fe5aeb081296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Ticker  baker_bros-2020_q3.csv  altimeter-2021_q1.csv  \\\n",
      "0   SGEN                       1                      0   \n",
      "1   BGNE                       1                      0   \n",
      "2   INCY                       1                      0   \n",
      "3   ACAD                       1                      0   \n",
      "4  ALXN1                       1                      0   \n",
      "5    KOD                       1                      0   \n",
      "6   BMRN                       1                      0   \n",
      "7   ASND                       1                      0   \n",
      "8   NVTA                       1                      0   \n",
      "9  MYOK1                       1                      0   \n",
      "\n",
      "   altimeter-2019_q4.csv  baker_bros-2020_q2.csv  coatue-2019_q3.csv  \\\n",
      "0                      0                       1                   0   \n",
      "1                      0                       1                   0   \n",
      "2                      0                       1                   0   \n",
      "3                      0                       1                   0   \n",
      "4                      0                       1                   0   \n",
      "5                      0                       1                   0   \n",
      "6                      0                       1                   0   \n",
      "7                      0                       1                   0   \n",
      "8                      0                       1                   0   \n",
      "9                      0                       1                   0   \n",
      "\n",
      "   fundsmith-2019_q3.csv  baillie_gifford-2020_q4.csv  altimeter-2021_q2.csv  \\\n",
      "0                      0                            1                      0   \n",
      "1                      0                            1                      0   \n",
      "2                      0                            1                      0   \n",
      "3                      0                            1                      0   \n",
      "4                      0                            0                      0   \n",
      "5                      0                            0                      0   \n",
      "6                      0                            1                      0   \n",
      "7                      0                            1                      0   \n",
      "8                      0                            0                      0   \n",
      "9                      0                            1                      0   \n",
      "\n",
      "   altimeter-2021_q3.csv  ...  casdin-2020_q1.csv  dragoneer-2019_q3.csv  \\\n",
      "0                      0  ...                   0                      0   \n",
      "1                      0  ...                   0                      0   \n",
      "2                      0  ...                   0                      0   \n",
      "3                      0  ...                   0                      0   \n",
      "4                      0  ...                   0                      0   \n",
      "5                      0  ...                   0                      0   \n",
      "6                      0  ...                   0                      0   \n",
      "7                      0  ...                   0                      0   \n",
      "8                      0  ...                   1                      0   \n",
      "9                      0  ...                   1                      0   \n",
      "\n",
      "   nikko-2020_q4.csv  tiger_global-2019_q3.csv  dragoneer-2021_q4.csv  \\\n",
      "0                  0                         0                      0   \n",
      "1                  0                         0                      0   \n",
      "2                  1                         0                      0   \n",
      "3                  0                         0                      0   \n",
      "4                  0                         0                      0   \n",
      "5                  0                         0                      0   \n",
      "6                  0                         0                      0   \n",
      "7                  0                         0                      0   \n",
      "8                  1                         0                      0   \n",
      "9                  0                         0                      0   \n",
      "\n",
      "   perceptive-2020_q2.csv  casdin-2020_q2.csv  tiger_global-2021_q4.csv  \\\n",
      "0                       0                   0                         0   \n",
      "1                       0                   1                         0   \n",
      "2                       0                   0                         0   \n",
      "3                       0                   0                         0   \n",
      "4                       0                   0                         0   \n",
      "5                       1                   0                         0   \n",
      "6                       0                   0                         0   \n",
      "7                       0                   0                         0   \n",
      "8                       0                   1                         0   \n",
      "9                       1                   1                         0   \n",
      "\n",
      "   casdin-2020_q3.csv  perceptive-2020_q3.csv  \n",
      "0                   0                       0  \n",
      "1                   1                       0  \n",
      "2                   0                       0  \n",
      "3                   0                       0  \n",
      "4                   0                       0  \n",
      "5                   0                       1  \n",
      "6                   0                       0  \n",
      "7                   0                       0  \n",
      "8                   1                       0  \n",
      "9                   1                       1  \n",
      "\n",
      "[10 rows x 109 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Path to the directory containing CSV files\n",
    "directory = './Historical_Data_13F_Updated'\n",
    "\n",
    "# Initialize an empty dictionary to store the ticker presence data\n",
    "ticker_presence = {}\n",
    "\n",
    "# Get all CSV files from the directory\n",
    "csv_files = [f for f in os.listdir(directory) if f.endswith('.csv')]\n",
    "\n",
    "# Iterate over the files and extract unique tickers\n",
    "for csv_file in csv_files:\n",
    "    file_path = os.path.join(directory, csv_file)\n",
    "    df = pd.read_csv(file_path)\n",
    "    unique_tickers = df['Symbol'].unique()\n",
    "    \n",
    "    # Update the ticker presence for each file\n",
    "    for ticker in unique_tickers:\n",
    "        if ticker not in ticker_presence:\n",
    "            # Initialize a new entry in the dictionary with the current file\n",
    "            ticker_presence[ticker] = {file: 0 for file in csv_files}\n",
    "        # Mark the presence of the ticker in the current file\n",
    "        ticker_presence[ticker][csv_file] = 1\n",
    "\n",
    "# Create a DataFrame from the ticker presence dictionary\n",
    "one_hot_encoded_df = pd.DataFrame.from_dict(ticker_presence, orient='index')\n",
    "\n",
    "# Reset the index to get tickers as a column instead of an index\n",
    "one_hot_encoded_df.reset_index(inplace=True)\n",
    "one_hot_encoded_df.rename(columns={'index': 'Ticker'}, inplace=True)\n",
    "\n",
    "# The DataFrame 'one_hot_encoded_df' is your one-hot encoded DataFrame\n",
    "print(one_hot_encoded_df.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ff9232c3-8d9b-412b-af07-faf087d67ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the one_hot_encoded_df DataFrame to a CSV file\n",
    "one_hot_encoded_df.to_csv('biotech_hedge_fund_encoded_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c389a54a-c3ff-4b2c-8143-9149cc5b8bc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5b1b1e-cbfa-4493-b8d4-7ae2a195243f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
